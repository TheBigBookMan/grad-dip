## Fundamentals of AI and ML
### Basic AI concepts and terminologies
- **AI**- simulation of human intelligence by machines like computer systems
	- systems that perceive, reason, learn and act based on data performing tasks like humans would with human-intelligence, pattern recognitions, deciison making, problem solving
- **ML**- subset of AI focusing on building systems that learn from data to make predicitons or decisions
	- not being explicilty programmed, but algorithms detecting patterns and relationships in data to improve performance over time
- **Deep Learning**- subset of ML
	- involves neural networks that has many layers (deep)
	- can automatically learn features and representations within large amounts of data
	- common in image recognition, speech processing and natural language understanding
- **Neural Networks**- set of algorithms designed to recognise patterns
	- inspired by the structure of human brain
	- layers of interconnected nodes where each connection carries a weight and data flows through from input to output
	- each node may change the input in a certain wayu and weigh on where the next node will be fired
- **Computer Vision**- field of AI focused on allowingm achines to be able to detect through visual information like images and videos
- **Natural Language Processing (NLP)**- deals with the interaction between human language and machines provessing by understanding, interpreting and generating
- **Model**- used in ML, it has been trained on data to make predictions specifically from the data trained on, does not require being programmed to do the task
- **Algorithm**- takes an input and then a process of logic is performed to create a specific output
- **Training**- feeding data to the ML to be trained on for better pattern recnognition and creating relationships between the data
- **Inference**- process using trained ML models for making predictions on specific tasks ased on new, unseed data
- **Bias**- systematic errors in ML model predicitons due to prejudice assumptions during the learning process
- **Fairness**- ensuring ML models predictions are impartial and do not favor any group over others
- **Fit**- how well the ML models prediction match the actual data. 
- **Overfitting**- occurs when the model learns the data too well and performs poorly on unseen data because it just uses the trained data
- **LLM**- type of deep learning model trained on vast amount of text data to understand human-like-language (NLP)
- **Similarities between AI, ML, DL**-
	- enable machines to perform tasks that usually require human intelligence
	- use data to make decisions
	- using pattern recognition from trained data to make the predictions
- **DIfferences between AI, ML, DL**-
	- AI- broadest concept, encompassing any machine with human-like intelligence
	- ML- subset of AI focussing on algorithms that learn from data to make deicisions
	- DL- using neural networks with multiple layers to model intricate data patterns
- **Types of Inferencing**-
	- **Batch**- processing large number of data inputs at once, suitable for tasks where real-time responses aren't necessary
		- like having large chunks sent in periods
	- **Real-time**- data inputs individually as they arrive, these are immediate predictions or decisions, essential for instant responses
- **Types of Data**-
	- **Labeled**- data comes with tags and labels for annotation, this allows for identifying correct and incorrect output for each input- supervised learning
	- **Unlabeled**- no explicit tags, this is used in unsupervised learning to discover hidden patterns
	- **Tabular**- structured data organised in tables with rows and columns, common in databases and spreadsheets
	- **Time Series**- data points collected or recorded at specific time intervals, used in forecasting and trend analysis
	- **Image**- visual data formats like JPEG/ PNG and used in computer vision tasks
	- **Text**- data in textual format, such as documents, social media posts- used in NLP
	- **Structured**- organised and easily searchable often stored in relational databases
	- **Unstructured**- without predefined format, such as videos, images and free-text documents
- **Types of Learning**-
	- **Supervised**- using labeled data to explicilty tell the ML model what is correct and incorrect- regression (linear like stocks) or classification (categorical)
	- **Unsupervised**- uses unlaeled data to indeitfy patterns between the input and create clustering and associated tatsks (groups common inputs together to identify some sort of common pattern)
	- **Reinforcement**- agent learns to make decisions by performing actions in an environment to maximize cumulative rewards, used in robotics and game playing

### Identify practical use cases for AI
- **AI Is appropriate use case**- can enhance decisions making, automatig repetitive tasks, scaling solutions efficiently
	- **Assist human decision making**- 
		- **Healthcare**- ML models can analyse medical images (x-rays, MRI) to assist doctors in diagnosing conditions with higher accuracy
		- **Finance**- analyse stock market trends, help financial analysts make more informaed investment decisions
		- **Custtomer support**- NLP powered chatbots can resolve common customer issues, leaving human agents for more complext cases
	- **Solution Scalability**- 
		- **Personlised marketing**- based on tracking human behaviour, can tagert individuals more specifically based on their browsing
		- **Supply chain optimization**- forecasting models can predict demand, optimize inventory and reduce waste
		- **Content moderation**- automatically filter inappropriate content on social media platforms, scaling moderation to millions of users
	- **Automation**-
		- **Manufactoring**- robots can utomate quality control and assembly processes
		- **Smart home automation**- optimize energy consumption by learning usage patterns and controlling devices accordingly
		- **Fraud detection**- real-time ML models can flag suspicious transactions for financial institutions
- **AI is not appropriate use case**- AI/ML not always best approach, can use traditional programming or rule-based systems
	- **Cost-benefit analysis**
		- **Small-scale projects**- cost of implementing ML slutions can outweigh the benefits if volume of data is insufficient or decisions are straightforward
		- **Limited data available**- not enough historical data to train an effective model, rule based approach might be more efficient
		- **Long development time**- if project requires immediate implementation, developing ML model too time consuming
	- **When specific outcome is needed**
		- If task requires precise, deterministic output rather than probabilistic prediction, ML not suitable. eg accounting, legal contract generation where accuracy is critical, deterministic algoprithms are preferable
- **Selecting appropriate ML techniques for specific use cases**
	- **Regression**-
		- **Use**- predicting continous outcomes- stock prices, temperature forecases, house prices
		- **AWS**- Sagemaker can build, train and deploy regression models using bult-in algorithms
	- **Classification**-
		- **Use**- categorical data stored in distinct classes such as spam detection, disease diagnosis or sentimen analysis
		- **AWS**- Sagemaker built-in algorithms like XGBoost can be used for classification tasks
	- **Clustering**-
		- **Use**- grouping similar items together, such as customer segmentation, market analysis or document clustering
		- **AWS**- Sagemaer supports clustering algorithms like K-means
- **Identify examples of real world AI applications**
	- **Computer Vision**-
		- **Use**- autonomous vehicles, facial recognition for security, quality control in manufaction, agriculture food sorting
		- **AWS**- Rekognition for image and video analysis
	- **Natural Language Processing**-
		- **Use**- customer support chatbots, sentiment analysis, document summarisation
		- **AWS**- Comprehend for extracting insights from text data
	- **Speech Recognition**-
		- **Use**- Transcribing customer support calls, voice-activated assistants (Alexa)
		- **AWS**- Transcribe for converting speech to text
	- **Recommendation Systems**-
		- **Use**- E-commerce product recommendations, movie suggestions on streaming platforms
		- **AWS**- Personalize for real-time personalised recommendations
	- **Fraud Detection**-
		- **Use**- Identifying fradulent credit card transactions, preventing identity theft
		- **AWS**- Sagemaker anomoly detection models
	- **Forecasting**-
		- **Use**- Demand forecasting, inventory management, resource planning
		- **AWS**- Forecast for time-series forecasting
- **Capabilities for AWS ML Services**
	- **Sagemaker**- fully managed service that helps data scientists and devs build, train, deploy ML models at scale. Supports variety of ML algorithms, automated model turning and model deployment
	- **Transcribe**- Automated speech recognition service converst speech into text. Useful for transcription of audio files, meeting recordings or real time speech
	- **Translate**- neural machine translation ervice that provides fast and accurate language translation, ideal for translating customer communications or documents
	- **Comprehend**- NLP service uses ML to extract key phrases, entities, sentiment and language from unstructured text. useful for customer feedback, social media monitoring and document classification
	- **Lex**- building conversational interfaces using voice and text. Powers chatbots and virtual assistants with automatic speech recognition and NLP
	- **Polly**- Text to speech service that converts written text into lifelike spoeech. Ideal for applications requiring voice interaction, like virtual assistants or audio content generation
### Describe ML Development Lifecycle
- The development lifecycle of how machine learning pipeline works
	1. **Data Collection**-
		- Purpose- gather data from various sources like databases, APIs, IoT devices to use for training
		- AWS- S3 for dat astorage, Glue for data extraction and transformation
	2. **Exploratory Data Analysis (EDA)**-
		- Purpose- understand the data by visualising patterns, outliers and data imbalances, make assumptions of the data
		- AWS- Sagemaker Data Wrangler for exploratory data analysis and data visualisation, QuickSight for business intelligence tool
	3. **Data Pre-Processing**-
		- Purpose- Clean and prepare the data, including handling missing values, normalization, and transofrmation- preparing the data to be trained, data needs to be to a certain standard for training to work properly
		- AWS- Sagemaker Processing for batch data pre-processing and Glue for multiple data sources connections
	4. **Feature Engineering**-
		- Purpose- Create new features or modify existing ones to improve the model performance
		- AWS- Sagemaker Feature Store for managing and storing features
	5. **Model Training**- 
		- Purpose- train ML models on labeeled data
		- AWS- Sagemaker Training Jobs for distributed and efficient training, Deep Learning AMIs
	6. **Hyperparameter Tuning**-
		- Purpose- Optimize model hyperparameters to improve performance
		- AWS- Sagemaker Automatic Model Tuning for hyperparameter optimization
	7. **Model Evaluation**-
		- Purpose- Assess model performance using metrics like accuracy, precision, recall and AUC
		- AWS- Sagemaker Experiments to track evaluation metrics and compare results, Cloudwatch Logs for tracking of performance
	8. **Deployment**-
		- Purpose- Deplo trained model for real-time or batch inference
		- AWS- Sagemaker Endpoint for real-time deployment, AWS Lamdbda for lightweight deployment
	9. **Monitoring**-
		- Purpose- Monitor the deployed model for drift, performance degradation or errors and make adjustments- loop through again
		- AWS- Sagemaker Model Monitor for automated monitoring, Cloudwatch Metrics for evaluation of stats
- **Sources of Models**- 
	-  **Open-Source Pre-Trained Models**
		- Hugging Face Transformers, Tensorflow Hub, PyTorch Hub
		- Reduces development time by leverageing state of the art models by large companies, ready to go code with higher abstraction
	- **Training Custom Models**
		- Created from scratch using specific data tailored to business problem
		- Sagemaker offers support for custom model training using tensorflow, pyorch and MXNet
- **Methods to Use a Model in Production**-
	- **Managed API Service**-
		- Deploy model using services like Sagemaker Endpoints, which handle scaling and availability
		- AWS- API Gateway + SageMaker Endpoint
	- **Self-Hosted API**-
		- Host model on custom servers or containers using Docker and Kubernetes
		- AWS- EC2, EKS
- **Fundamental Concepts of MLOps**-
	- **Experimentation**-
		- Iterative model development using different datasets, algorithms and hyperparameters- to see what sort of matching variables work best
		- AWS- Sagemaker Experiments to track and manage experiments
	- **Repeatable Processes**-
		- Automate ML pipelines for consistend and reproducible results- be able to consistently output the same method with automative processes
		- AWS- Step Functions + Sagemaker Pipelines
	- **Scalable Systems**-
		- Ensure ML solutions scale with increasing data and users- using things like containers, auto balancers, load balancers for scalability
		- AWS- Sagemaker Training with managed spot instances for scalability
	- **Managing Technical Debt**-
		- Minimise complexity by maintaining clear and modular piplelines- ensuring it doesnt get too complicated to manage and deply the ML pipline
	- **Production Readiness**-
		- Validate models before deployment using robust testing frameworks- ensuring that the model being used has based a baseline minimum so its not trash
	- **Model Monitoring and Re-Training**-
		- Continously monitor model performance and retrain using updated data- after identifying issues 
		- AWS- Sagemaker Model Monitor + Sagemaker Pipinelines for retraining
- **Model Performance Metrics**-
	- **Model Metrics**- 
		- **Accuracy**- percentage of correct predictions out of total predictions
		- **Precision**- ratio of true positives to all predicted positives
		- **Recall**- ratio of true positive to all actual positives
		- **F1 Score**- harmonic mean of precisions and recall, balancing both
		- **Area Under the ROC Curve (AUC)**- measure the models ability to distinguish between classes
	- **Business Metrics**-
		- **Cost per User**- operational cost divided by the number of users benefiting from the model
		- **Development Costs**- resources (time, infrastructure) spent on model development
		- **Customer Feedback**- direct feedbacj from end-users on the models usefulness and accuracy
		- **Return on INvestment (ROI)**- value derived from the model compared to its cost of development and maintenance
- **AWS Managed AI/ML Services for ML Lifecycle**-
	- **Sagemaker**- end-to-end ML development, including training, deployment and monitoring
	- **Sagemaker Data Wrangler**- simplified data preparation and exploration
	- **Sagemaker Feature Store**- centralised repository for storing and retrieving ML features
	- **Sagemaker Model Monitor**- automatic monitoring of deployed models for data drift and errors
	- **Sagemaker Pipelines**- automate and manage ML workflows

## Fundamentals of Gen AI
### Basic Concepts of Gen AI
- **Foundational Gen AI Concepts**-
	- **Tokens**- 
		- Smalles unit of text or data that a model processes, LLM tokens could represent words, characters or subwords
		- Example- AI is fun tokenise as ["AI", "is", "fun"]- this depends on how the tokeniser does it, as it could be split into singular characters as well
	- **Chunking**- 
		- Dviding data into manageable chunks for efficient processing, like splitting a long document into smaller sections before feeding it to the model
		- usefule in tasks like summarisation or document processing
	- **Embeddings**-
		- Dense vector representation of data (text, images) where similar items are closer in a vector space
		- Example- Word2Vec creates embeddings where synonyms like "king" and "queen" are geometrically close- like categorising words that are related in a way together in a 3D space (vectors)
	- **Vectors**- 
		- Numeric representations of data (embeddings), vectors enable computational efficiency in similarity search or clustering tasks- the vectors are stored like etc like nested coordinates on a 3D plane
	- **Prompt Engineering**-
		- crafting specific intructions to prompt to the model to guide the gen AIs behaviour
	- **Transformer-Based LLM**- 
		- LLM built on transformer architecture use self-attention mechanisms to understand context across entire sequences- the ability to understand and remember better
		- good at tasks like translation, summarisation and text generation
	- **FOundation Models**-
		- large pre-trained models capable of being fine-tuned for a variety of downstream tasks, they form the foundation for many AI applications
		- OpenAI GPT models, hugging face models, AWS Bedrock models
	- **Multi-modal Models**-
		- Models designed to process and generate data across multiple modalities (text, image, video)
		- DALL-E generates images from text
	- **Diffusion Models**-
		- generative model that creates data by iteraveily removing noise, used for image generation and restoration
		- Stable diffusion, DALL-E
- **Use Cases for Gen AI**-
	- **Image Generation**-
		- DALL-E and stable diffusion use text-to-image prompting
		- Use- marketing, social media, digital art
	- **Video Generation**-
		- Generate animated or syntheised videos based on text descriptions or templates
		- Use- virtual characters, movie effects
	- **Audio Generation**-
		- Text-to-soeech and AI generated music
		- Use- accessibility with like reading out to blind people
	- **Summarisation**-
		- Condensing long documents into concise summaries using LLMs
		- Use- news aggregation, legal document analysis
	- **Chatbots**-
		- Conversational agents poweredby LLMs 
		- Use- customer support, virtual assistants
	- **Translation**-
		- Gen models like AWS Trranslate provide context-aware language translation
		- Use- cross-language translation, content localisation
	- **Code Generation**-
		- Github Copilot assist developers by generating boilerplate code or solving problems
		- Use- software development, debugging
	- **Customer Service Agents**-
		- Agents handle customer queries with human-like responses
		- Use- e-commerce, banking
	- **Search**-
		- Context-aware search engines provide accurate results using embeddings and LLMs
		- Use- knwoeldge managementm, document search
	- **Recommendation Engines**-
		- Personalised reocmmendations using user behasviour and embeddings
		- Use- e-commenrce, streaming platforms
- **Foundation Model Lifecycle**-
	1. **Data Selection**-
		- identify diverse, high-quality datasets for pre-training
		- Example- text data from books, websites and research articles
	2. **Model Selection**-
		- Choose architecture best suited for the problem (eg GPT for test, diffusion for images)
		- Example- GPT for NLP tasks
	3. **Pre-Training**-
		- Train the model on a vast corpus of data to learn generalised representations
		- AWS- Sagemaker supports large-scale distribured training
	4. **Fine-Tuning**-
		- Adapt the model to specific use cases or industries using domain-specific datasets
		- AWS- Sagemaker fine-tuning for customising foundation models
	5. **Evaluation**-
		- Assess models performance using metrics like BLEU (text) FID (images)
		- AWS- Sagemaker Experiments to track evaluation results
	6. **Deployment**-
		- Make model available via APIs or endpoints for real-time batch inference
		- AWS- Sagemaker Endpoint for managed deployment
	7. **Feedback**-
		- Gather user feedback to idetnfiy areas of improvement
		- Example- continous monitoring of chatbot interactions
	8. **Model Iteration**-
		- Retrain or fine-tune model periodically to incorporate feedback and updated data
		- AWS- Sagemaker Pipelines for automating retraining workflows
- **AWS Gen AI Services**-
	- **Sagemaker**- end-to-end development and deployment of generative models
	- **Polly**- text-to-speech for audio generation
	- **Translate**- language translation services
	- **Rekognition**- image and video analysis for visual AI tasks
	- **Lambda**- lightweight deployment of gen AI models for scalable APIs
### Capabilities and Limitations of Gen AI For Business Problems
- **Advantages**-
	- **Adaptability**-
		- Gen AI models can adapt to different tasks and data types without requiring extensive retraining
		- Example- LLM fine-tuned for customer support, code generation or content createion
		- Business- reduces time to market for custom AI solutions
	- **Responsiveness**-
		- Gen AI can provide real-time responses, enhancing user experience
		- Example- chatbots using LLMs offer quick and contextual customer support
		- Business- improces customer satisfaction and reduces operational costs
	- **Simplicity**-
		- Gen AI automates complex tasks, reducing need for human intervention
		- Example- automatic code completion tools like co-pilot to simplify programming
		- Business- streamline workflows, enabling businesses to focus on strategic objectives
	- **Creativity & Innovation**-
		- Create novel outputs, like art, music or marketing content based on prompts
		- Eample- DALL-E generate custom visuals from text prompts
		- Business- enhance creativity in marketing, product design and content generation
	- **Cross-Domain Functionality**-
		- Process multimodal inputs (text, image, audio) for diverse applications
		- Example- multi-modal models handle visual and text-based customer queries simultaneously
		- Business- expand AI applicability across industries
- **Disadvantages**-
	- **Hallucinations**- 
		- May produce outputs that are factually incorrect or fabricated
		- Example- chatbot confidently provides incorrect answers to customer queries
		- Impact- reduces trust and reliability, especially incritical apps like finance and healthcare
	- **Interpretability**-
		- AI models operate as black boxes making their decision-making process hard to explain
		- Example- LLM may produce recommendation without clear reasoning
		- Impact- hinders adoption in regulated industries requiring transparency
	- **Inaccuracy**-
		- Generate outputs with errors or misinterprate data, especially for niche domains and if the training wasnt enough data
		- Example- translating domain-specific jargon incorrectly
		- Impact- Leads to potential miscoummunication or suboptimal decisions
	- **Non-determinism**-
		- Can produce different outputs from the same input, making them less predictable
		- Example- repeated prompts to a model yield various responses
		- Impact- challenges concistency in apps like legal or financial document generation
	- **Data and Resource Constraints**-
		- Training or fine-tuning generative AI models requires significant computational resources and high-quality data
		- Impact- limits accessibility for small businessses and increases costs
- **Factors for Selecting Appropriate Gen AI Models**-
	- **Model Types**-
		- Choose between LLM, diffusion models or multi-modal models based on the task
		- Example- GPT for text, stable diffusion for image generation
	- **Performance Requirements**-
		- Assess latency, throughput and accuracy needs
		- Example- real-time chatbots require low-latency models
	- **Capabilities**- 
		- Ensure model supports desired functionalities
		- Example- Multi-modal models for processing text and images
	- **Constraints**-
		- Factor in computational resources, cost and scalability
		- Example- Smaller models may be more cost-effective but less capable
	- **Compliance**-
		- Ensure the model meets industry regulations and ethical standards
		- Example- Healthcare apps require HIPAA-compliant AI systems
	- **AWS services**-
		- Bedrock provides access to foundation models for text, image and other generative tasks
		- Sagemaker offers pre-trained gen AI models with eay fine-tuning options
- **Determine Business Value for Gen AI Apps**-
	- **Business Value**- Gen AI can transform businesses by
		- **Increasing Efficiency**- automative repetitive tasks reduces operational costs
		- **Enhancing Customer Experience**- real-time, accurate responses build trust and satisfaction
		- **Driving Innovation**- creative outputs provide unique competitive advantages
	- **Metrics to Evaluate Success**-
		- **Cross-Domain Performance**-
			- The models ability to perform well across multiple tasks and domains
			- Example- multi-modal models performance in text summarisation and image generation
		- **Efficiency**-
			- Processing time, resource usage, cost-effictiveness
			- Example- Cost per inference and computational overhead
		- **Conversion Rate**-
			- Percentage of users who take desired actions due to gen AIs output
			- Example- improved purchase rates from personalised product recommendations
		- **Average Revenue Per User (ARPU)**-
			- Revenue generated per user due to enhanced services
			- Example- IMproved purchase rates from personalised product recommendations
		- **Accuracy**-
			- Precision of outputs compared to expected results
			- Example- Correctness of translations or summaries
		- **Customer Lifetime Value (CLV)**-
			- Total revenue from a customer over their lifetime with the business
			- Example- Enchanced loyalty through AI-powered personalised experiences
- **AWS Services to Support GEN Apps**
	- **Bedrock**- access foundation models for text and iamge generation
	- **Sagemaker**- build, traing, deploy custom gen AI models
	- **Polly**- generate human-like speech for audio apps
	- **Translate**- perform accurate translations using gen NLP models
	- **Rekognition**- analyse images and videos for gen AI apps
	- **Lex**- build conversational AI cahtbots pwoered with LLMs

### AWS Infrastructure and Technologies for Building Gen AI Apps
- **Key AWS Services for Gen AI**-
	- **Sagemaker Jumpstart**- 
		- pre trained models and pre-built solutions for quick deployment
		- Use- easily deploy text generation, image generation and summarisation models
	- **Bedrock**-
		- Access to foundation models from providers Anthropic, Stability AI, AI21 Labs without infrastructre management
		- Use- text generation, chatbots, recommendation systems
	- **Partyock (Bedrock playground)**-
		- User-friendly interface for experimenting with and fine-tuning foundation models on bedrock
		- Use- prototype generative AI apps without deep techincal expertise
	- **Q**-
		- Specialised service for querying gen AI models and managing user interactions
		- Use- advanced NLP tasks and model interaction
	- **Lamdba**-
		- Serverless computing for lightweight, scalable deployments of AI apps
		- Use- deploy inference endpoints for real-time gen apps
	- **Elastic Kubernetes Service**- 
		- orchestration for deploying custom gen AI models using docker containers
		- Use- manage scalable deployments of models like GPT or diffusiuon models
	- **Inferentia**-
		- custom designed chips for cost-effective ML inference
		- Use- enhance performance of gen AI apps during inference
	- **S3**-
		- scalable storage for large datasets, such as text copora, image libraries ror audio files
		- Use- store training data for pre-training or fine-tuning foundation models
- **Advantages Using AWS Gen AI Services**-
	- **Accessibility**-
		- no need for expertse managing AI infrastructure or training models from scratch
		- Services like bedrock provide pre-trained models accessible via APIs
	- **Lower Barrier Entry**-
		- Pre-built solutions in Sagemaker Jumpstart enable businsess to get started without in-depth AI knowledge
		- Example- deploy chatbot in minutes with minimal config
	- **Efficiency**-
		- Optimize resource usage with services like Inferentia and Elastic Inferentia
		- Pre-configured workflows in sagemaker pipeline reduce dev time
	- **Cost-Effictiveness**-
		- Pay-as-you-go pricing minimses upfront ivnestments
		- Managed services reduce operational overhead for maintaining infrastructure
	- **Speed to Market**-
		- quickly prototype ad deploy gen AI solutions using bedrock and partyrock
		- Example- launching a personalised recommendation engine within days
	- **Meet Business Objectives**-
		- Customisable models and APIs ensure alignment with specific business goals
		- Example- fine-tuning a language model to improve customer support efficiency
- **Benefits of AWS Infrastructure for Gen AI Apps**-
	- **Security**-
		- end-to-end encryption ensures the safety of sensitive data
		- IAM allows fine-grained permissions
	- **Compliance**-
		- AWS complies with global standards, GDPR, HIPAA, SOC 2
		- ideal for industries like healthcare and finance that require strict regulatory adherence
	- **Responsbility**-
		- Shared responsibility model clarifies roles between AWS (infrastructure security) and customers (app security)
	- **Safety**-
		- tools like Macie and Security Hub proactively detect vulnerabilities and ensure data safety
	- **Scalability and Reliability**-
		- auto-scaling features allow apps to handle variable workloads
		- multi-region availability ensures low latency and high availability for global apps
- **Cost Tradeoffs of AWS Gen AI Services**
	- **Responsiveness**-
		- Tradeoff- real-time inferencing requires low-latency endponints, which increase costs
		- Example- sagemaker real-time endpoints cost more than batch inference jobs
	- **Availability**-
		- Tradeoff- deploying across multiple regions improves availability but incurs additional costs
		- Example- hosting endpoints in both US and Europe icnreases latency coverage but adds data transfer costs
	- **Redundancy**-
		- Tradeoff- high redundancy ensures reliability but increases resource usage
		- Example- using multiple Sagemaker endpoints with a load balancer adds fault tolerance
	- **Performance**-
		- Tradeoff- high performance hardware (inferentia or GPUs) speeds up inference but costs more
		- Example- Inferentia chips are cost-effective for high-throughput tasks compared to general-purpose CPUs
	- **Regional Coverage**-
		- Tradeoff- serving global customers may require deplyoing in multple AWS regions impacing operational costs
		- Example- latency-sensitive apps require regional endpoints for better user exeriences
	- **Token-Based pricing**-
		- Tradeoff- many foundation models available via Bedrock charge based on token usage
		- Example- heavy usage of LLMs with long prompts and outputs can lead to higher costs
	- **Provisioned Throughput**-
		- Tradeoff- reserved throughput ensures consistent performance but increases baseline costs
		- Example- provisioning for peak usage may result in underutilisation during off-peak hours
	- **Custom Models**-
		- Tradeoff- training custom models adds complexity and resource demands compared to leveraging pre-trained ones
		- Example- fine-tuning requires compute-intensive resources, but delivers higher task-specific performance