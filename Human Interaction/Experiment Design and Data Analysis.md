## Experiment Design
- 3 important steps of HCI are design, implement and evaluate a computing system
- learning to conduct and design an experiemnt is a skill in research
- **Experiment Design**-
	- process of deciding what variables (independent variables, dependent variables, control variables and random variables) to use
	- what tasks and procedures to use
	- how many participants to use 
	- how to solicit them
- **Control Experiement**-
	- make sure to control for outside variables that may influence the results and cause skewed data
- **Methodology**-
	- way an experiment is designed and carrie dout
	- involves deciding on people (participants), the hardware and software (materials or apparatus), the tasks, the order of tasks, the procedure for briefing and preparing the participants, the variables, the data collected and analysed and so on
	- havig sound methodology is critical
	- need to follow standards for experiments with human participants and not just make it up because it seems reasonable
	- American Psychological Society (APA) is predominant organisation promoting research in psych- the improvement of research methods and conditions and the application of research findings
- **Ethics Approval**-
	- crucial step that precedes every HCI experiment
	- experiments involve humans and therefore researchers must respect safety, welfare and dignity of human participants in their research and treat them equally and fairly
	- researchers need to submit documents to review committee to apply for ethics approval
	- typically review committee serves to ensure several ethical guidelines are aknowledged and adhered to
	- important to include the right of the participant to be informaed of
		- the nature of the research (hypotheses, goals, objectives)
		- research methodology (medical procedures, questionaiires, participant observeation)
		- any risks or beenfits
		- right not to participate, not to answer any questions and/or terminate participation at any time without prejudice (without academic penalty, withdrawl or remuneration)
		- right to anonymity and confidentiality
- **Getting Started with Experiment Design**-
	- need to begin with the question: What are the experimental variables?
	- variables are the factors and conditions you can modify and measure in the experiment and properly formed research questions inherently identify experimental variables
	- **Hypotheses**-
		- statement of predicted or expected relationshup between at least two variables
		- provisional answer to a research question
		- to form a good hypotheses we need to define the variables inbolved and define a relationshup between the variables
		- five standards for good hypotheses:
			- **Testable**-
				- manipulating the variables and/pr measuring the outcome variable must potentially exist
			- **Falsifiable**-
				- must be able to disprove the hypothesis with data
			- **Concise**-
				- should be stated in simplest adequate form
			- **Precise**-
				- should be specific (operationalised)
			- **Useful**-
				- should relate to existing theories and/or point towards new theories
				- should lead to studies beyond the present one
				- hard to determine in advance
	- **Independent Variables**-
		- circumstance or characteristic that is manipulated in an experiment to elicit a change in human response while interacting with computer
		- represensts the cause or reason for an outcome
		- 'independent' because they are independent of participant behavour (nothing a participant can do to influence an independent variable
		- example- interface, device, feedback mode, button layout, visual layout, age, gender, background noise, expertise etc
		- synoym of factor
		- must have two levels
			- the two levels, values or settings for an IV are the test conditions
			- name both the factor and level
			- ![[Pasted image 20250811124520.png]]
		- human charactersitics are naturally occurring attributes- age, gender, height, weight, handedness, grip strength, finger width, visual acuity, personality trait, political viewpoint, first language, shoe size etc
		- cannot be manipulated in the same way as an attribute of an interface
		- experiment must have atleast 1 IV but possible to have more
		- higher number of effects increases rapidly with size of experiement
			- ie two IVs = 2 effects and 1 interaction effect
	- **Dependent Variables**-
		- IV are the variables that the experimenter changes to test their dependent vairables
		- a change in the IV directly causes a change in the DV
		- the effect on the DV is measured and recorded
		- a DV is a measured human behaviour- related to an aspect of the interaction involving an IV
		- they are 'dependent' because they depend on what the participant foes
		- example- task completion time, speed, accuracy, error rate, throughput, target re-entries, task retries, presses of backspace etc
		- dependent variables must be clearly defined aso that the other researchers can reproduce your study
		- any observable, measurable behaviour is a legit DV (provided it has the potential to reveal differences among the test conditions)
		- novel DV- 'negative facial expressions' 
	- **Control Variables**-
		- many circumstances or factors that (might influence a dependent variable but are not under investigation)
		- these need to be accommodated in some manner
		- best to control them
		- examples- room lighting, room temperature, background noise, display size, mouse shape, mouse cursor speed, keyboard angle, chair height etc
		- not always things you would think about, but they exist and may influence a DV
		- controlling them means they are fixed at a nominal setting during the experiment so they do not interfere
		- they might interfere if they are set at an extreme value
		- allowing such circumstances to exist at a fixed nominal value is typical in experiment research
		- the circumstances are treated as control variables
		- a control variable is a circumstance (not under investigation) that is kept constant while testing the effect of an IV
		- it is not a variable of interest in the study but it is controlled because it could influence the outcomes
		- more control means the experiment is less generaliseable (less applicale to other people and other situations)
	- **Random Variables**-
		- instead of controlling all circumstances or factors, some allowed to vary randomly
		- values of random variables as representing random sample of all values or instances of that variable
		- there is a cost since more variability is introduced in measures
		- is a benefit since results are more generalisable
		- tpically random variables pertain to characterstics of the participants including biometrics (height, weight etc), social disposition (relaxed, nervous etc) or even genetics (gender, IQ)- these charactersitcsi are allowed to vary at random
	- **Confounding Variables**-
		- any circumstnace or condition that changes systematically with an IV is a confounding variable
		- unlike control or random variables, confounding are usually problematic in experimental research
		- is the effect observed due to the IV or to confounding variable
		- researchers must attune to the possible presense of a confounding variable and elimnate it, adjust for it or consider in someway
		- otherwise effects observed may be incorrectly interpreted
		- example- setups can use different technology when trying to measure the one thing, and the result isnt a reflection of the persons behaviour, its a result because of the different technology (irrelevant)
- **Experiment Task**-
	- experiment task must 'elicit' a change
	- when participants are given a test condition they are asked to do a task while their performance is measured
	- later they are given a different test condition- another level of the IV and asked to do the task again
	- the choice of task is important
	- **Two Objectives for Designing a Good Task**-
		- **Represent**-
			- representative task of the activities people do with the interface
		- **Discriminate**-
			- can discriminate the test conditons
		- Something in the interaction that differentiates the test conditions, toherwise there is no research to conduct
	- **Task Examples**-
		- if we have a research idea that involves developing a new graphical method for entering equations in a spreadsheet, we can design an experiemnt task: inserting an equation using
			- the graphical method
			- the conventional method
		- if we have a research idea that involves developing an auditory feedback technique for programming a GPS device, we can design an experiment task: programming a destination location into a GPS device using
			- auditory feedback method
			- converntional method
	- **Knowledge-based Tasks**-
		- most experiment tasks are performance based or skills based (eg insertting an equation, programming a destination location)
		- somtimes the task is knowledge based (eg use an internet search interface to find the date)
		- participants can become contaminated after the first run of the task, since they have the acquired knowledge
		- this is why need a ccreative approach for the other test condition to change slightly
- **Experiment Procedure**-
	- procedure ecompossaes everything with the participants
		- arriving, welcoming
		- signing a consent form
		- instructions given to participants about the experiment task
		- demonstration trials, practice trials
		- rest breaks
		- administering of a questionnaire or an interview
	- **Instructions**-
		- instructions to participants are important
		- often goal of experiment task is 'to proceed as quickly and accurately as posible but at a pace that is comfortable'
		- other isntructions are fine as the goal of the experiment or the nature of the tasks 
		- important to give the same instructions to all participants
		- if participant asks for clarification, do not change instructions in a way that may cause participant to behave differently from other participants
	- **Participants**-
		- researchers want experimental results to apply to people not actually tested- a population
		- these examples include computer-literate adults, teenagers, children, people with certain disabilites, left-handed people, engineers etc
		- applying results to people other than those who were tested is possible, two conditions required
			- the people tested must be members of the same population of people to whom results are assumed to hold
			- enough participants must be tested
				- this is more to do with statistical testing than with the similarly of participants to the population
		- ideally participants used in a n experiment are selected at random from the population
		- participants are typically solicited from a convenient pool of individuals (as its hard to always be completely random as not enough people readily available)
		- need to consider how many participants we need for an experiment
		- the results can fail if too small or too large
			- common way to find the best amount is by looking at sample sizes from similar research
	- **Questionnaires**
		 - questionnaires are used in most HCI experiments for two main purposes
		- **Participant Information**- to collect information baout the participants such as demographics and prior experience with interfaces or interaction techniques related to the research
		- ![[Pasted image 20250819084109.png]]
		- **Feedback**-
			- To solicit feedback, comments, impressions, suggesions and so on about participants use of experiment apparatus
			- NASA Task Load INdex (NASA-TLX) is a popular tool for measuring and conducting a subjective mental workload (MWL) assessment
			- can be used to deteremine the MWL of a participant while they are performing a task
			- rates performance across 6 dimensions to determine an overall workload rating
				1. **Mental Demaind**- how much thinking, deciding or calculating was required to perform the task
				2. **Physical Demand**- amount of intensity of physucal activity required to complete the task
				3. **Temporal Demand**- amount of time pressure involved in completing the task
				4. **Effort**- how hard does the participant have to work to maintain their level of performance
				5. **Performance**- level of success in completing the task
				6. **Frustration**- how insecure, discouraged, secure or content the participant felt during the task
			- **Likert Scale**-
				- common rating system in questionnaires
				- is designed to measure peoples attitudes, opinions or perceptions
				- subjects choose from a range of responses to a specific question or statemet
				- ![[Pasted image 20250819084518.png]]
- **Experiment Design**-
	- Two ways to assign conditions to participants
		- **Within Subjects**-
			- each participant is tested on each condition
			- if experiment has IV with 3 test conditions, then each participant needs to complete the 3 conditions
			- ![[Pasted image 20250819084822.png]]
		- **Between Subjects**-
			- each participant is tested on one condition only
			- if experiment has 3 test contiions, participant only needs to complete 1 condition
			- ![[Pasted image 20250819084908.png]]
	- **Counterbalancing in Experimental Design**-
		- can mitigate order effects of the within-subjects design by counterbalancing
			- participants are divided into groups
			- test conditions are administered in a different order to each group
		- Three ways a test conditions can be ordered
			- **Latin Square**-
				- is an n x n array filled with n different symbols
				- each occurring exactly once in each row and exactly once in each col
				- distinguishing property is that each condition occurs precisely once in each row and col
				- ![[Pasted image 20250819085100.png]]
			- **Use all Possible Orders**-
				- all orders (n!) can be used 
				- ![[Pasted image 20250819085124.png]]
			- **Randomise Conditions**-
				- conditions can be randomised
				- best if tasks are brief and repeated often, such as target size, movement direction and movement distance
				- ![[Pasted image 20250819085210.png]]
			- **Longitudinal Studies**-
				- above focuses on confounding influence of learning in experiments where IV is assigned within subjects
				- learning effects/order effects- are problematic and must be accomodated in some way, such as counterbalancing
				- sometimes the research has a particular interest in learning, or acquisition of skill
				- the experimental procedure involves testing users over a prolonged period while their improvement performance is measured
				- instead of eliminating learning, the research seeks to observe it and measure it
				- experimental evaluation where participants practice over a prolonged period is called a longitudinal study
				- 'amount of practice' is an IV
				- participants perform the task over multiple units of testing while their improvement with practice is observed and measured
				- each unit of testing is a level of the IV
				- various names are used for the IV, but typically example (session1, session2 etc)
				- example of experiment comparing 2 text-entry methods for mobile phones: multi-tap and Letterwise
					- for english text entry, letterwise requires average of 44% fewer keystrokes than does multi-tap
					-  However, a performance benefit might not appear immediately, since users must learn the technique. 
					- Furthermore, learning occurs with both methods, as participants become familiar with the experimental procedure and task. 
					- However, it was felt that the reduction in keystrokes with LetterWise would eventually produce higher text-entry speeds. 
					- To test this, a longitudinal study was conducted, with entry method assigned between subjects. The results are shown in the figure below.
					- Indeed, the conjectured improvement with practice was observed. 
					- Initial entry speeds were about 7.3 words per minute (WPM) for both methods in session 1.
					- ![[Pasted image 20250819092650.png]]

## Data Analysis
- after collecting experiment data, we need to use statistical procedures to answer research questions
- **Hypothesis Testing**-
	- statistical hypothesis test is a method of statistical infereence used to decide whether the data at hand sufficiently support a particular hypothesis
	- **Assumption of No Difference**-
		- null hypothesis
		- no difference between testing methods
		- statistical procedures seek to reject or accept the null hypothesis
	- Two types for hypothesis testing
		- distinguishing feature is that parametric tests operate on data from a probability distribution like normal distribution or t-distribution, whereas non-parametric tests are distribution free- which means they make no assumption about the distribution of the underlying data
		- **Parametric Tests**-
			- can be used to analyse typical performance measurements such as time, speed or accuracy for doing tasks, or counts for events such as key presses, finger flicks, gaze shifts or target re-entries
			- analysis of variance (ANOVA) is main statistical procedure for hypothesis testing in factorial experiment (experimental design is used to study 2 or more factors, each with multiple discrete values)
				- collection of statistical models and their associated estimation procedures (such as variation among andbetween groupos) used to analyse the differences among means
				- the ANOVA result is typically reported in parathenses as support for a statement indicating whether the outcome of test was statistically significant
				- **Several types of ANOVA**-
					- **One-way ANOVA**-
						- used in an experiment with 1 IV
						- eg testing for differences among 2+ levels
						- goal of one-way ANOVA is to deteremine if IV has significant effect on DV
						- the goal is to determine if the test conditions yield different outcomes on the DV (eg one of the test conditions is faster/slower than the other)
						- majority of HCI research papers that describe experiments include the results of an ANOVA, giving F-statistic, the degrees of freedom
						- common task in HCI is to compare 2+ intefaces or interaction techniques to deteremine which is superior performance on one or more DV, such as task completion time, error rate, task re-tries etc
						- ![[Pasted image 20250820092818.png]]
						- ![[Pasted image 20250820092826.png]]
						- 
					- **Factorial ANOVA**-
						- used when there is more than 1 factor
						- eg 2-way ANOVA is used in an experiment with 2 IV
					- **Repeated Measures ANOVA**-
						- when the same subjects are used for each factor
						- research design that involves multiple measures of the same variable taken on the same or matched subjects under different conditions
						- commonly used statistical approach to repeated measure designs
						- the repeated-measure factor (qualitative IV) is the within-subjects factor, while dependent quantitative variable on which each participant is measured is the DV
						- ![[Pasted image 20250820093251.png]]
			- **Main Effects**-
				- is the effect of 1 of the IV on the DV, ignoring the effects of all other IV
			- **Interaction Effects**-
				- represent the combined effects of the IV on the DV
				- when an interaction is present, the impact of 1 IV depends on the level of the other IV
				- ![[Pasted image 20250820093640.png]]
				- ![[Pasted image 20250820093649.png]]
			- **Post-hoc Test**-
				- for an IV that has 2+ levels, there is a significant effect
				- while this means atleast 1 test condition different significantly from one other test condition, it does not indicate which test conditions different significantly from one another
				- to deteremine which pairs differ significantly, a post-hoc comparisons test is used
				- for example- we found a significant main effect for target size on movement time
				- to compare group means, we need to perform post-hoc tests, also known  multiple comparisons, example- small size vs large size on movement time
		- **Non-parametric Tests**-
			- methods of statistical analysis that do not require a distrubution to meet the required assumptions to be analysed- especially if the data is not normally distributed
			- due to this reason, sometimes referred to as distribution-free tests
			- described as they are typically used in HCI research- to analyse ordinal (sometimes interval data)
			- data are typically obtained through questionnaires (likert scales), preference ratings or assessments on a scale
			- rather than using direct measurement of human responses, the data are obtained subjectively, from participants, or using heuristics or other non-empirical or semi-empirical methods
			- four most common non-parametric procedures are
				- Mann-Whitney U test
				- Wilcoxon signed-rank test
				- Kruskal-Wallis test
				- Friedman test
				- ![[Pasted image 20250820095517.png]]
			- **Wilcoxon Signed-Rank Test**-
				- ![[Pasted image 20250820095542.png]]