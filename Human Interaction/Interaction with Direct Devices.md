## Touchscreen Interaction
- touch is thought to be the first sense humans develop
- sense of touch, tactile sense is made up of exceptionally fine network of receptors in ytour skin
- **Sensors for Finger Input Detection**-
	- two main types of screen sensors for finder input detection
		- **Resistive Touchscreen**-
			- works based on pressure applied to the screen
			- consists of several layers
			- when screen is pressed, the outer layer is pushed onto the next layer
			- the technology senses the pressure is being applied and registers input
			- while versatile as they can be used with finger, fingernail, stylus or any other object
			- they are used on pen-based interfaces
		- **Capacitive Touchscreens**-
			- work by sensing the conductive properties of an object usually the skin on your fingertip
			- screen on a mobile phone or smartphone usually has a glass face and does not rely on pressure
			- makes it more responsive than resistive screen when it comes to gestures such as swiping and pinching
			- can only be touched with a finger (some conductive pens)
			- will not respond to touches with a regular stylus, gloves or most other objects
	- actions like swiping through contact lists, zooming in and out of web pages and maps, scrolling though photos are best suited to capacitive touchscreens, unlike resistive screens you can swipe across them gently and still get a response
- **Touchscreens vs Touchpads**-
	- compare through 3 aspects- 
		- **Precision**-
			- **Touchscreens**-
				- Low
				- the contact area of fingertup is greater than a single x, y coordinate, which increases the chances of uninteded command activiations
				- mouse and pen/stylus supply a precise x, y coordinate
			- **Touchpads**-
				- High
				- same as a mouse
		- **Object State**-
			- **Touchscreens**-
				- two state model
				- touch surface of a display device is either touched (on) or not (off)
				- no hover state that ca n trigger additional visual feedback
			- **Touchpads**-
				- same as touch
		- **Rich Interaction**-
			- **Touchscreens**-
				- supports multitouch
				- multiple input points (fingertips) on a touch surface
				- supports direct manipulation of objects through gestures such as tapping, dragging, sliding, pinching and rotating
			- **Touchpads**-
				- same as touch
				- no support for direct manipulation as they are indirect input devices
- **Two-State Model**-
	- direct finger touch uses a two-state model
		- touch surface of a display device is either touched (on) or not (off)
		- there is no hover state that can trigger addiitional visual feedback
		- ![[Pasted image 20250805094126.png]]
- **Multitouch**-
	- multitouch tech that enables a touchpad or touchscreen to recognise more than one point of contact with the surface
	- apple added in multi-touch with additional functionality such as pinch, zoom or to activate certain subroutines to predefined gestures
	- increases the degree of freedom for finger input
	- commonly a finger can just offer two degrees of freedom (x, y coordinates) which is required for pointing tasks
	- higher degrees of freedom can be achieved with more fingers engaged in interaction tasks
	- multitouch tech can be used to perform other tasks such as zooming and rotation- which is significant advantage of the multitouch technology
	- current multiotouch tech are actually multippoint because they only rely on information of x,y coordinates
- **Finger Properties**-
	- classified into 4 main categories
		- **Position Property**
			- coordinage value (x,y)
		- **Motion Property**-
			- velcoity
			- acceleration
		- **Physical Property**-
			- size of contact area
			- shape of contact area
			- orientation
			- pressure
		- **Even Property**-
			- finger tap
			- finger flick
	- The contact position of the finger is the first property considered in widget design
	- most touchscreen devices can detect and track single point on the touch panel of device
	- touch interaction design also considered finger movement velocity and acceleration
	- dictionary entries include a variety of motions and may take form of dedicated computer app
	- researchers also investigated finger physucal properties
		- when finger lands on a touchscreen there are physical properties such as finger contact area, finger orientation and finger pressure that can be used to enhance finger interaction
		- ![[Pasted image 20250806085529.png]]
	- finger tapping is typically adopted to simluate the mouse click event. finger flicking is a quick movement on the screen and used as the primary navigation gesture
- **Fat Finger Problem**-
	- when selecting targets on touch device with a finger and the targets are smaller than the size of the finger contact area users do not know if they hit the desired target
	- lack of sensing precision can make precise touchscreen interactions more difficult and error prone
	- in many interfaces touch targets are packed too close toegether resulting in wrong button being touched which ends up as incorrect input
	- **Solutions**-
		- **Pinch Gesture**-
			- enlarge the target to be selected
			- user touches screen with two or more fingers and moves them apart to zoom in
		- **Shift**-
			- facilitate target selection on touchscreen
			- Scenario 1
				1. user touches screen intending to acquire small target located near other targets; shift determines the presense of targets small enough to be occluded by the finger
				2. to eliminate occlusion, shift 'escalates' by creating a callout that contains a copy of the occluded screen area placed in a non occluded location on the screen; the callout includes a pointer representing the finger contact point to eliminate selection point abiguity
				3. the user fine-tunes the pointer position while maintaing contact with the screen
				4. once the correct position is visually verified, lifting the finger to select the target
				5. removes the callout
			- Scenario 2
				- when acquiring a large target, shift behaves differently. occlusion is not a problem in this case, so shift does not escalate by default.
				- lifting their finger immediately, user makes selection as if using an unaided touchscreen
				- ![[Pasted image 20250807151238.png]]
		- **Lucidtouch**-
			- is a mobile device that is 'pseudo transparent'
			- allows users to see their fingers through the screen
			- users interact with screen contents using multiple fingers on the back of the device
			- this solves the problem that traditional touchscreens are facing; it prevents the users fingers from occluding screen contents

## Pen Interaction
- pen interaction has attacted a lot of attention in HCI
- a stylus (digital pen) is a small, pen shaped instrument used to input commands to a computer screen, mobile device or graphics tablet
- user places a stylus on the surface of the screen to draw or make selections by tapping the stylus on the screen
- stylus can be used instead of a mouse or trackpad
- **Pen Computing**-
	- follows a pen-paper metaphor
	- fundamental way for capturing daily experiences, communicating ideas, recording notable events and conducting deep thinking and visual descriptions
- **Properties of Pen Input**-
	- 