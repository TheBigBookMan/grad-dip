- **Human-Computer Interaction (HCI)**-
	- research in the design and use of computer tech
	- focuses on interfaces between peoploe and computers
	- users input commands with keyboard, mouse, gamepad, joystick or microphone
	- input information handled by OS kernal and middleware
	- computer outputs processed information via displays, speakers or gamepage
	- users then input new commands after receiving feedback
	- forming an input/output loop
	- situated at the intersection of computer science, psyhcology and all other fields of science
- **Why HCI Important**-
	- need HCI to improve user interface design
	- feedback loop of human sensors
	- ![[Pasted image 20250724095423.png]]
- **User Interfaces**- 
	- **Batch Interfaces (1945-68)**-
		- non-interactive user interfaces
		- users specified all details of batch job in advance of bath processing, receives output when all processing is done
		- computer does not prompt for furhter input after processing has started
		- mainly punch cards
	- **Command Line INterfaces (1969-present)**-
		- prompt users for input by typing command string with keyboard abd respond by outputting text on computer monitor
	- **Graphical User Interface (GUI) (1968-present)**-
		- input via devices such as computer keyboard and mouse that provide a articulated graphical output via computer monotir
		- WIMP (windows, icons, menus, pointers)
- **Interface Types**-
	- **Pen Interfaces**-
		- any computer user interface using a digital pen
		- popular in mobiles such as tablets, PDAs and GPS receivers
		- digital pen is generally used to press upon a graphics tablet or touchscreen, as opposed to using a more traditional interface such as keyboard, keypad, mouse or touchpad
	- **Direct Touch Interfaces**-
		- multi-touch technology enabling surface (touchpad or touchscreen) to recognise presence of one or more point of contact with surface at any time
		- used to implement additional functionality such as pinch to zoom, or activate certain subroutinrs attached to predefined gestures
	- **Tangible User Interfaces**-
		- person interacts with digital information through physical environment
		- GUI only exists in digital world, TUI connects the digital with physical
		- because this is designed for one target group, interface must be developed together wth target group ensuring better user experience
		- allows phyiscal interaction between user and interface itself
		- user knows intuitively how to use interface by knowing the function of phyiscal object- less learning time
	- **Gesture Interfaces**-
		- form of non-verbal communication which visible bodily actions are used to communicate messages
		- in place of speech or together in parallel with spoken words
		- include movements of hands, face or body parts
		- **Gesture Design**- 
			- gestures should be straightforward so users can easily recall and perform them
			- simple gestures allow users to use technology minimal effort at max speed
		- **Gesture Recognition**-
			- rely on gesture-recognition algrithms to identify gesture movements
			- systems determine which device command a particular gesture represents and take appropriate action
	- **Voice User Interfaces**-
		- allow users to interact with a system through voice or speech commands
		- usually use speech recognition to understand spoken commands
		- widely used in motor vehicles, home automation systems, computer OS, home applicanes and TV remotes
	- **Brain Computer Interfaces**- 
		- acquires brain signals, analyses them and translates them into commands relayed to an output to carry out action
		- computer interaction via application of ML to statistical temporal features  extracted from frontal lobe EEG brainwave
		- data have high levels of success in classifying mental states and emotional states

## Input Devices and Interaction Tasks
- **Interacation Task**- 
	- entry of information using a hardware or software device
	- dialogue is a series of exchanges o information between a user and the computer
	- seven basic tasks in HCI
- **Selection**-
	- choosing objects from set of alternatives
	- selection task may be achieved by pointing and clicking object with mouse cursor; tabbing through list; selecting meny; typing identifier key; soeaking speech recognition
	- like a dropdown list to select
- **Position and Orient**-
	- specfying a position within a range, an angle or 3D orientation
	- like clicking a show your locationm button
	- **Linguistic**- 'specify' in some coordinate systems
		- typing in the specific coordination manually
		- can use input text boxes to quantify position, orientation and scale of an bobject
	- **Spatial**- move cursor to position
		- moving a position with a cursor
		- use arrow buttons or mouse cursor to change position and orientation of an objet by selection
		- device movement direction should correspond to movement in screen space
- **Path**- specifying a series of positions and orientations oer time like a plan your map
- **Quantify**- specifying an exact numeric value like data
- **Linguistic**- value types on QWERTY keyboard or number pad
- **Spatial**- can use an operate slider, dial, pointer and up/down counter a slider
- **Text**- entry of symbolic data
	- when entering large amounts of text, hardware keyboard is preferred over simluated keyboard or selection of characters

## Input Devices
- input devices in HCI enables users to enter data as instruction into computer for processing
- keyboard, mouse, scanner, touch pad, light pen, digital camera, hoysticsk
- **Categories**-
	- **Sense Positions**-
		- sense position of mechanical control object (stylus or finger)
		- tablets, phones
	- **Sense Motion**-
		- sense their motion, mouse use light source- light-emitting diode (LED) and light detector to detect movement relative to a surface
		- mouse
	- **Sense Force**-
		- sense force applied to device
		- isometric joystick
		- pointing device typically mounted centrally in a computer keyboard
		- like other pointing devices- mice, touchpadds or trackballs, OS software translates manipulation of device into movements of pointer or cursor
		- reacts to strain or force rathern than gross movement- called isometric pointing device 
	- **Absolute vs Relative Input Devices**-
		- **Absolute**- 
			- 1:1 mapping between input and output spaces
			- position sensing devices like tablet
			- things like tablet because you are moving directly from one edge to another with real space the same as on screen space
		- **Relative**-
			- input controls the relative position of the cursor (always indirect)
			- motion sensing devices like hte mouse
			- example is cursor because you move a few cm may equal inches on the screen
	- **Direct vs Indirect Control**-
		- **Indirect Devices**-
			- display surface is not input surface
			- a mouse is an indirect input device as you must move mouse to point to a spot on screen
			- hovering is indispensable, user must know position of cursor before starting drawing
			- hovering feedback means tracking position of the pointing device while pointing device is proximal to interaction surface
		- **Direct Devices**-
			- display surface also is input surface
			- touchscreen is direct input device
			- hovering feedback is not indispensiable as there is clear mapping between pen/finger and screen
			- occlusion problems are main drawback- concerned with cases where fingers or hands cover the object of interestg when intetaction with it
			- occlusion proglem is the fat finger problem, when touch targets are packed too close together the finger touches more than what desired
- **Transfer Function**-
	- matches physical properies sensed by input device
	- three main tytpes:
		- force-to-velocity (isometric joystick)-
		- position-to-position (touchscreens)-
		- velocity-to-velocity (mice and touchpads)-
	- simple miltiplicative transfer function is control-to-display (C:D) ratio which is ratio between movement of input device and corresponding movement of object it controls
	- if a mouse must be moved 1cm on desk in order t move a cursor 2 cm on screen the device has a 1:2 control-to-display ratio
	- essentially how far you nee dto move the mouse to match whats on the screen
- **Three State Models**- different states for an input 
	- computer pointing devices in terms of state transitions
	- paradigm of descriptive modelling
	- example- mouse
		- **State 0**- out of range- the device is not in its physical tracking range
		- **State 1**- tracking- device motion moves only the cursor
		- **State 2**- dragging- device motion moves objects on the screen
	- **Device Acquisition Time**- 
		- average time to pick up or putdown an input device
		- important metric to measure performance of input device
		- mobile devices supporting pen input and finger touch, device acquisition time using a pen is generally longer than using finger which demonstrated significant advantage of direct finger touch
	- **Degrees of Freedom**- 
		- number of parameters may vary independently
		- traditional GUI is moving on 2D cursor (y, x) which is 2 degrees of freedom
		- sensing the location of two fingers would be 4DOF, two touch points can be used as X and Y position of object as well as rotation and scale

## Graphical User Interface (GUI)
- **GUI Programming**-
	- use a toolkit that must follow a pattern of progtram design laid down by toolkit vendor
	- toolkits are set of reuseable classes designed to provide useful, general purpose functionality
	- each toolkit has its own API and set of design rules
	- most languages have a popular toolkit to use
- **GUI Programming Terms**-
	- **Window**- 
		- area of screen controlled by application
		- usually rectangular 
		- windows can contain other windows and every single GUI control is treated as a window in its own right
	- **Control**-
		- GUI object used for controlling the applicaiton
		- controls have properties and usually generate events
		- normally controls correspond to app level objects and the events are coupled to methods of corresponding object such when an event occurs- when an object executes a method
		- GUI environment usually provides a mechanism for binding events to methods
	- **Widget**-
		- is a control sometimes restricted to visible controls
		- some cotnrols can be associated with a given window but are not visible
		- widgets are subset of controls that are visisble and can be manipulated by programmer, such as frame, label, button, text entry, message boxes, test box, radio button, canvas, check button, image, listbox, menu/menu button and scale/scrollbar
	- **Layout**-
		- controls are laid out within frame 
		- layout may be specific in number of ways either using on screen coordinates specified in pixels, using relative postion to other components (left, top) or using grid or table arrangement
		- coordinate system is easy to undertand but difficult to manage when window is resized and so on
		- beginners are advised to use non-resizeable windows if working with coordiante based layouts
	- **Child**-
		- GUI apps have hierarchy of widegets/controls
		- top-level frame comprising of application window will contain subframes that contain more frames or controls
		- controls can be visualised as a tree structure with each control having a single parent and number of children
		- normal for structure to be stored explicitly by widgets so programmers can perform some common action to control and all its children