- **Human-Computer Interaction (HCI)**-
	- research in the design and use of computer tech
	- focuses on interfaces between peoploe and computers
	- users input commands with keyboard, mouse, gamepad, joystick or microphone
	- input information handled by OS kernal and middleware
	- computer outputs processed information via displays, speakers or gamepage
	- users then input new commands after receiving feedback
	- forming an input/output loop
	- situated at the intersection of computer science, psyhcology and all other fields of science
- **Why HCI Important**-
	- need HCI to improve user interface design
	- feedback loop of human sensors
	- ![[Pasted image 20250724095423.png]]
- **User Interfaces**- 
	- **Batch Interfaces (1945-68)**-
		- non-interactive user interfaces
		- users specified all details of batch job in advance of bath processing, receives output when all processing is done
		- computer does not prompt for furhter input after processing has started
		- mainly punch cards
	- **Command Line INterfaces (1969-present)**-
		- prompt users for input by typing command string with keyboard abd respond by outputting text on computer monitor
	- **Graphical User Interface (GUI) (1968-present)**-
		- input via devices such as computer keyboard and mouse that provide a articulated graphical output via computer monotir
		- WIMP (windows, icons, menus, pointers)
- **Interface Types**-
	- **Pen Interfaces**-
		- any computer user interface using a digital pen
		- popular in mobiles such as tablets, PDAs and GPS receivers
		- digital pen is generally used to press upon a graphics tablet or touchscreen, as opposed to using a more traditional interface such as keyboard, keypad, mouse or touchpad
	- **Direct Touch Interfaces**-
		- multi-touch technology enabling surface (touchpad or touchscreen) to recognise presence of one or more point of contact with surface at any time
		- used to implement additional functionality such as pinch to zoom, or activate certain subroutinrs attached to predefined gestures
	- **Tangible User Interfaces**-
		- person interacts with digital information through physical environment
		- GUI only exists in digital world, TUI connects the digital with physical
		- because this is designed for one target group, interface must be developed together wth target group ensuring better user experience
		- allows phyiscal interaction between user and interface itself
		- user knows intuitively how to use interface by knowing the function of phyiscal object- less learning time
	- **Gesture Interfaces**-
		- form of non-verbal communication which visible bodily actions are used to communicate messages
		- in place of speech or together in parallel with spoken words
		- include movements of hands, face or body parts
		- **Gesture Design**- 
			- gestures should be straightforward so users can easily recall and perform them
			- simple gestures allow users to use technology minimal effort at max speed
		- **Gesture Recognition**-
			- rely on gesture-recognition algrithms to identify gesture movements
			- systems determine which device command a particular gesture represents and take appropriate action
	- **Voice User Interfaces**-
		- allow users to interact with a system through voice or speech commands
		- usually use speech recognition to understand spoken commands
		- widely used in motor vehicles, home automation systems, computer OS, home applicanes and TV remotes
	- **Brain Computer Interfaces**- 
		- acquires brain signals, analyses them and translates them into commands relayed to an output to carry out action
		- computer interaction via application of ML to statistical temporal features  extracted from frontal lobe EEG brainwave
		- data have high levels of success in classifying mental states and emotional states

## Input Devices and Interaction Tasks
- **Interacation. Task**- 
	- entry of information using a hardware or software device
	- dialogue is a series of exchanges o information between a user and the computer
	- seven basic tasks in HCI
- **Selection**-
	- choosing objects from set of alternatives
	- selection task may be achieved by pointing and clicking object with mouse cursor; tabbing through list; selecting meny; typing identifier key; soeaking speech recognition
- **Position and Orient**-
	- specfying a position within a range, an angle or 3D orientation
	- **Linguistic**- 'specify' in some coordinate systems
		- can use input text boxes to quantify position, orientation and scale of an bobject
	- **Spatial**- move cursor to position
		- use arrow buttons or mouse cursor to change position and orientation of an objet by selection
		- device movement direction should correspond to movement in screen space
- **Path**- specifying a series of positions and orientations oer time
- **Quantify**- specifying an exact numeric value
- **Linguistic**- value types on QWERTY keyboard or number pad
- **Spatial**- can use an operate slider, dial, pointer and up/down counter
- **Text**- entry of symbolic data
	- when entering large amounts of text, hardware keyboard is preferred over simluated keyboard or selection of characters

## Input Devices
- input devices in HCI enables users to enter data as instruction into computer for processing
- keyboard, mouse, scanner, touch pad, light pen, digital camera, hoysticsk
- **Categories**-
	- **Sense Positions**-
		- sense position of mechanical control object (stylus or finger)
		- tablets, phones
	- **Sense Motion**-
		- sense their motion, mouse use light source- light-emitting diode (LED) and light detector to detect movement relative to a surface
		- mouse
	- **Sense Force**-
		- sense force applied to device
		- isometric joystick
		- pointing device typically mounted centrally in a computer keyboard
		- like other pointing devices- mice, touchpadds or trackballs, OS software translates manipulation of device into movements of pointer or cursor
		- reacts to strain or force rathern than gross movement- called isometric pointing device 
	- **Absolute vs Relative Input Devices**-
		- **Absolute**- 
			- 1:1 mapping between input and output spaces
			- position sensing devices like tablet
		- **Relative**-
			- input controls the relative position of the cursor (always indirect)
			- motion sensing devices like hte mouse
	- **Direct vs Indirect Control**-
		- **Indirect Devices**-
			- display surface is not input surface
			- a mouse is an indirect input device as you must move mouse to point to a spot on screen
			- hovering is indispensable, user must know position of cursor before starting drawing
			- hovering feedback means tracking position of the pointing device while pointing device is proximal to interaction surface
		- **Direct Devices**-
			- display surface also is input surface
			- touchscreen is direct input device
			- hovering feedback is not indispensiable as there is clear mapping between pen/finger and screen
			- occlusion problems are main drawback- concerned with cases where fingers or hands cover the object of interestg when intetaction with it
			- occlusion proglem is the fat finger problem, when touch targets are packed too close together the finger touches more than what desired
- **Transfer Function**-
	- matches physical properies sensed by input device
	- three main tytpes:
		- force-to-velocity (isometric joystick)-
		- position-to-position (touchscreens)-
		- velocity-to-velocity (mice and touchpads)-
	- simple miltiplicative transfer function is control-to-display (C:D) ratio which is ratio between movement of input device and corresponding movement of object it controls
	- if a mouse must be moved 1cm on desk in order t move a cursor 2 cm on screen the device has a 1:2 control-to-display ratio
- **Three State Models**- different states for an input 
	- example- mouse
		- **State 0**- out of range- the device is not in its physical tracking range
		- **State 1**- tracking- device motion moves only the cursor
		- **State 2**- dragging- device motion moves objects on the screen