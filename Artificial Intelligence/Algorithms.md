## State Space Search
- looking at different possibilities before making a decision
- like looking at all possible routes to a destination and then choosing the shortest and best based on criteria
- **Back-tracking**- some paths may lead to dead-end so we go back to the previous choice-point and try an alternative
- **State**- 
	- description of a scenario (time, location, capability)
	- Initial/starting state is the intiail state of the problem to be solved
	- goal/final state is the state to be achieved
	- state is like a snapshot where entities currently are in terms of time, location, capability where it may change
	- if an entity (dog) is starting a certain state (2) and it needs to reach state 8 for its other entity (treats)
		- starting state at(dog, 2) at(treats, 8)
		- goal state at(dog, X) at(treats, X)
- **State Space**- 
	- tree structure
	- each node of the tree represents a state
	- initial state is the root of the tree
	- if node A is a parent of node B, then it is viable to move from state A to state B
	- the goal state may/may not be a node in the tree
	- can think of it like each child node is a possibility of action from the parent node (they have to be connected somehow)
	- nodes can be in multiple branches (if there are multiple ways to connect to it)
	- sometimes the goal state can be on multiple branches (occurs in state space multiple times)
	- sometimes the goal state will be on no branches  (not in the state space)
- trying to identify the shortest path from the initial state to the goal state
- **Constructing State Space**- representation of states is critical when solcing problem using state space search. good representation can have a dramatic effect on the amount of computation required and could mean the difference between solcing and not solving the problem
	- General structure for search problems
		1. Starting state
			- starting city
			- current state of a two player game like chess
		2. Goal state (or a test for goal state)
			- destination city
			- winning state of the game (checkmate)
		3. Permissible operators
			- go to city X
			- move queen to position X
	- Seeing what the intiail state would be for the problem, what the end state is and what are the possible moves that can be done for the entity to get from the start start to the goal state
- **State Space Search**- 
	- involves finding a path from the intiail state of a search problem to the goal state in the state space
	- in planning and robotics, the path from the intitial state to the goal state is also called a plan
	- it represents a sequence of actions to be taken to achieve the goal
	- **Plan**- the different nodes for the state that are used to reach the goal from the initial

## Blind Search (breadth-first, depth-first, depth-first with depth limit)
- **Breadth-first search**-
	- explores the state space lebel-by-level
	- uses a queue- first in first out
	- only when no more states to be explored at a given level it moves on to the next level
	- goes by the levels of the tree, may take a while to get to the bottom of a singular branch if they are all long as it has to clear every parent node off that level
	- does not maintain a list of states on the current path (however you can if path is required by storing ancestor information along with each state)
		- so much rapid changing of branches as need to get all off the level
	- can construct solution by tracing back along the parents from the goal state to the start state
	- all nodes at level *n* are examinded before proceeding to level *n +1* , if it finds a solution then it is a **guaranteed to be shortest path to the goal**
	- **GUaranteed shortest path** - if there are several solutions its gauarnteed to find shortest solution first
		- good for problems where its known that a simple solution exists
	- if bad branching factor (average number of descendents per node) cam soon lead to an explosion of states that need to be kept in memory (exponential function of path length at any time)
	- if each state has an average of B children, then nu mnber of states oin a given level is B times the number of states on previous level *Bn* states on level *n*
		- because each child will have a parent and then have multiple children as well
	- if all Open list, then combinatorially explosive nature of the space may prevent finding a soltuion
	- Space Complexity makes it impractical for large problems
- **Depth-first search**- 
	- When a state is examined, all of its children and their descendents are examined before its siblings
	- uses stack- first in last out
	- Moves vertically down a branch before moving on to the next branch
	- will iterate through all descendants of a node before moving on to a sibling
	- gets quickly into a deep search space
	- if its known that solution path will be long, it doesnt waste time searching several shallw states in the graph
	- can get lost deep in a graph, missing shorter paths to a goal
	- at each level, the list open retains only the children of a single state, if a graph has an average of B children per state, this requires a toal space usage of *B n* states to go *n* levels deep into the space
- **Depth-first search with depth limit**-
	- good compromise between breadth-first and depth-first
	- set a global depth limit and dont explore if the depth is greater than that limit
		- the depth bound forces a failure on a search path once it has reached a certain level
		- results in a breath-like sweep of the search space at that depth level
	- most appropriate if it is known that a solution lies within a certain depth
	- can create the depth limit to be:
		- based on certain amount of resources that you have, needing to save on computation so splitting the amount across branches 
		- how many snapshots of state can be made within the probem, like in a game where you can only make a certain amount of moves then thats the depth limit
- **Evaluating search strategies**- 
	- four factors for evaluating
		1. **Completeness**- 
			- a search is complete if it is guaranteed to find a solution if there is one
			- not all search techniques are complete
		2. **Time Complexity**-
			- how long does it take to find a solution
			- usually measured in terms of the number of nodes expanded
		3. **Space Complexity**-
			- how much space is used by the algorithm
			- usually measured in terms of the max size that the nodes list becomes during the search
		4. **Optimality/Admissibility**-
			- if a solution is found, is it guaranteed to be an optimal one, that is is it the one with the minimum cost
	- **Evaluation Breadth-first**
		- Completeness- Yes
		- Time Complexity- 1 + b + b^2 + b^3 ... + b^n = O(b^d)
			- worst case scenario (big O notation) it will have to go through every branch on every level to reach the goal
		- Space Complexity- O(b^d)
		- Optimality/Admissibility- Yes
		- b = branching factor, d = depth of solution
	- **Evaluation Depth-first**
		- Completeness- No
		- Time Complexity- O(b^m)
			- worst case scenatio it goes to the max depth of branches, which could be massive
		- Space Complexity- O(bm)
		- Optimal/Admissibility- No
			- because it could go around on a branch for a long time to reach the goal (if goal connected to multiple parents)- where one goal could be shorter, but it just didnt start on that branch
		- b = branching factor, m = max depth of tree search
	- **Evaluation Depth-first wth Depth-limit**
		- Completeness- Yes if l > d
		- Time Complexity- O(b^l)
		- Space Complexity- O(bl)
		- Optimal/Admissibility- No
		- b = branching factor, d = depth of solution, l is depth limit
	- **Evaluation depth-first search with iterative deepening (ID)**
		- This is where the depth consistently geets deeper with every iteration
		- Checks all nodes at current depth limit before increasing depth limit
		- Completeness- Yes
		- Time Complexity- O(b^d)
		- Space Complexity- O(b^d)
		- Optimality/Admissibility- Yes
		- b = branching factor, d = depth of solution
	- **Evaluation of O(bd)**
		- Completeness- Yes if l > d
		- Time Complexity- 1 + (1 + b) + (1 + b + b^2)... = O(b^d)
		- Space Complexity- O(bd)
		- Optimality/Admissibility- Yes
		- b = branching factor, d is depth of solution

## Heuristic Search (Best-first, A*, Hill climbing and Simulated Annleaing search)
- Comparison between blind search and heuristic search
	- **Blind Search**
		- depth-first and breadth-first strategies do not consider information about preferred states
		- no capability of determining if one state is better (like closer to the goal), this is why called blind/uninformed/exhaustive
		- blind search searches through a state space indiscriminately
		- usually very ineffecient, by adding a domain knoweldge we can improve search processes 
	- **Heuristic Search**
		- in contrast to blind search, heuristic have some idea of how close state is to the goal (this means it can explore the more promising states first)
		- heuristic evaluation function that determines which state to select to continue the search
		- explore the node that is most likely to be nearest to goal state using the heuristic function which tells us how close we are to the goal state
		- no guaranteee heuristic function will return a value that ensures a node is closer to gal state than another node
		- implement heuristic function, need to have domain knoweldge so the heuristic function has to know something about the problem so it can judge how close the current state is to the goal state
- **Heuristic Function**- *f(n)* = estimated distance between the state *n* and the goal state
	- definition of *f(n)* is problem dependent
- **Best-first search (greedy search)**- 
	- similar to depth-first and breath-fiorst, uses list OPEN to keep track of current fringe of the search and CLOSED record states already visited
	- this includes added step of ordering the states on OPEN according to the heuristic function- the closeness of these states to the goal
	- On each iteration the search, it alwas selects the most "promising" state (with the lowest heuristic function value) in OPEN to perform search, thus OPEN is actually a priority queue
	- each step it will look at the ordered OPEN list and choose the best heuristic function (lowest score = estimated closer to goal) and this is why greedy because always choosing the best selection
- **Uniform Cost Search**- sometimes edges in state space is associated with a cost- so determining the search for goal state AND the lowest cost path to the goal state
	- breadth-first search finds the shallowest goal state and therefore be the cheapest solution provided the **path cost is a function of the deppth of the solution**, but if it is not the case, then breadth fierst is not gauranteed to find the best (cheapest) solution
	- Uniform cost search remedies this by expanding the lowest cost node on the fringe, where cost is the path cost from starting state to the current state *g(n)* 